{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf13c827",
   "metadata": {},
   "source": [
    "\n",
    "### Classification using a Simple Neural Network on MNIST Dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a7e80",
   "metadata": {},
   "source": [
    "In this example, we will use the TensorFlow library to create a simple neural network-based classification model for the MNIST dataset. The MNIST dataset consists of handwritten digits (0-9) and is a popular benchmark dataset for image classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7832ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (1.20.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (20.9)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.29.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (23.1.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging->tensorflow) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries:\n",
    "!pip install tensorflow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f03327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries:\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5196a77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Loading and preprocessing the MNIST dataset:\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalizing the pixel values to be between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Converting the labels to one-hot encoded vectors\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0afd8e",
   "metadata": {},
   "source": [
    "The dataset is split into a training set (60,000 samples) and a test set (10,000 samples). We normalize the pixel values to be between 0 and 1 and convert the labels to one-hot encoded vectors for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd62e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definning the neural network model:\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding a Flatten layer to convert 2D images to 1D arrays\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Adding a Dense hidden layer with 128 units and a ReLU activation function\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Adding a Dense output layer with 10 units (for 10 classes) and a softmax activation function\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a79211c",
   "metadata": {},
   "source": [
    "We create a sequential model and add three layers: a Flatten layer to convert the 2D images (28x28 pixels) into 1D arrays, a Dense hidden layer with 128 units and a ReLU activation function, and a Dense output layer with 10 units (for the 10 classes) and a softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42b990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model:\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998fdfd1",
   "metadata": {},
   "source": [
    "We compile the model using the Adam optimizer, categorical cross-entropy loss, and accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8911fd7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.2792 - accuracy: 0.9207 - val_loss: 0.1242 - val_accuracy: 0.9662\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1241 - accuracy: 0.9628 - val_loss: 0.0946 - val_accuracy: 0.9723\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0861 - accuracy: 0.9741 - val_loss: 0.0950 - val_accuracy: 0.9717\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0630 - accuracy: 0.9811 - val_loss: 0.0785 - val_accuracy: 0.9768\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0495 - accuracy: 0.9853 - val_loss: 0.0764 - val_accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: 0.0787 - val_accuracy: 0.9800\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.0769 - val_accuracy: 0.9807\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.0791 - val_accuracy: 0.9818\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0790 - val_accuracy: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f863db04850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model:\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32,\n",
    "          validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7365f9b",
   "metadata": {},
   "source": [
    "We train the model using the training data for 10 epochs with a batch size of 32 and a validation split of 10% to monitor the model's performance on unseen data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c82b25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0751 - accuracy: 0.9791\n",
      "Test accuracy: 0.9791\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model:\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364b8de",
   "metadata": {},
   "source": [
    "We evaluate the model on the test dataset and print the test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dfcf97",
   "metadata": {},
   "source": [
    "That's it! You now have a simple neural network-based classification model for the MNIST dataset. The model achieves a test accuracy of around 98%. We can further improve the model by adding more layers, using dropout or batch normalization, or adjusting the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c7146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
